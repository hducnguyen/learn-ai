{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as ai\n",
    "\n",
    "ai.configure(api_key = \"AIzaSyBj-V0yJ0fxgpyi23MhVr4yymGEmxeQx8A\")\n",
    "\n",
    "model = ai.GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're right! 2 + 2 is 4.  I must be having a bit of a math malfunction today. \n",
      "\n",
      "Let me know if you have any other questions. \n",
      "\n",
      "You got it! 4 multiplied by 2 is 8. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "chat_history.append({\"role\" : \"user\", \"parts\" : \"what is 2+2\"})\n",
    "chat_history.append({\"role\" : \"model\", \"parts\" : \"it is 4\"})\n",
    "\n",
    "chat_session = model.start_chat(history=chat_history)\n",
    "\n",
    "response = chat_session.send_message(\"No it is 100\")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.text)\n",
    "\n",
    "response = chat_session.send_message(\"take the answer and multiply by 2\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters: inputs  \n",
    "\n",
    "Candidate count = how many response you want to return ==> default to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## How to Learn \n"
     ]
    }
   ],
   "source": [
    "configs = ai.types.GenerationConfig(\n",
    "    candidate_count= 1, \n",
    "    # stop_sequences= [\"AI\", \"learn\"]\n",
    "    # max_output_tokens= 5 // maximum token output\n",
    "    #temperature=  // randomness of the answer (0.0 to 2.0) \n",
    ")\n",
    "\n",
    "res = model.generate_content(\"How to learn AI\", generation_config=configs)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file: Gói hồ sơ viết luận | URI: https://generativelanguage.googleapis.com/v1beta/files/548sy1xse8yx\n"
     ]
    }
   ],
   "source": [
    "my_file = \"Gói_Hồ_Sơ_Viết_Luận_ĐH.pdf\"\n",
    "\n",
    "uploaded_file = ai.upload_file(path= my_file, display_name=\"Gói hồ sơ viết luận\")\n",
    "\n",
    "print(f\"Uploaded file: {uploaded_file.display_name} | URI: {uploaded_file.uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved files Gói hồ sơ viết luận | URI: https://generativelanguage.googleapis.com/v1beta/files/548sy1xse8yx\n"
     ]
    }
   ],
   "source": [
    "retrieved_file = ai.get_file(name=uploaded_file.name)\n",
    "\n",
    "print(f\"Retrieved files {retrieved_file.display_name} | URI: {retrieved_file.uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.generate_content([retrieved_file, \"Hãy tóm tắt tài liệu này\"], stream=True)\n",
    "\n",
    "for chunk in res:\n",
    "    print(chunk.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
